{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load imports\n",
    "import os\n",
    "import librosa\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# Stabilization of tqdm\n",
    "tqdm.monitor_interval = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mute the noise and other small echoes in audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mute_noise(data_path, save_path, sampling_rate=44100, top_db=30):\n",
    "    for file in tqdm(os.listdir(data_path)):\n",
    "        # load audio file\n",
    "        audio = np.array(librosa.core.load(os.path.join(data_path, file), sampling_rate)[0])\n",
    "\n",
    "        # split the audio at desired db\n",
    "        split_audio = librosa.effects.split(audio, top_db)\n",
    "\n",
    "        # create new audio with repaced silences with zeros\n",
    "        new_audio = np.zeros(len(audio))\n",
    "        for i, split in enumerate(split_audio):\n",
    "            new_audio[split[0]:split[1]] = audio[split[0]:split[1]]\n",
    "\n",
    "        waveform_integers = np.int16(new_audio * 32767)\n",
    "\n",
    "        # save file with silences removed\n",
    "        write(os.path.join(save_path, ('trimmed_' + file)), sampling_rate, waveform_integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='./audio/'\n",
    "save_path='./trim_audio'\n",
    "\n",
    "# check if save path exists, else make it\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "mute_noise(data_path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mute the noise and other small echoes in audio, and chuck it to 1min intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mute_noise_chucked(data_path, save_path, sampling_rate=44100, top_db=30, trim_sec=60):\n",
    "    for file in tqdm(os.listdir(data_path)):\n",
    "        # make sure only audio files are loaded\n",
    "        if file.split('.')[-1] not in ['mp3', 'wav', 'm4a']: continue\n",
    "            \n",
    "        # load audio file\n",
    "        audio = np.array(librosa.core.load(os.path.join(data_path, file), sampling_rate)[0])\n",
    "\n",
    "        # split the audio at desired db\n",
    "        split_audio = librosa.effects.split(audio, top_db)\n",
    "\n",
    "        n = 0\n",
    "        \n",
    "        # create new audio with repaced silences with zeros\n",
    "        new_audio = np.zeros(split_audio[0][0])\n",
    "        for i, split in enumerate(split_audio):\n",
    "            if (len(new_audio) + split_audio[i][1]-split_audio[i][0]) > (sampling_rate*trim_sec):\n",
    "                # save file and create new array\n",
    "                write(os.path.join(save_path, (f\"{file.split('.')[0]}_noise_muted_{n}.{file.split('.')[1]}\")), \n",
    "                                               sampling_rate, np.int16(new_audio * 32767))\n",
    "                n += 1\n",
    "                new_audio = np.zeros(0)\n",
    "            new_audio = np.concatenate((new_audio, audio[split[0]:split[1]]))\n",
    "            if i < len(split_audio)-1:\n",
    "                if (len(new_audio) + split_audio[i+1][0]-split_audio[i][1]) > (sampling_rate*trim_sec):\n",
    "                    # save file and create new array\n",
    "                    write(os.path.join(save_path, (f\"{file.split('.')[0]}_noise_muted_{n}.{file.split('.')[1]}\")), \n",
    "                                                   sampling_rate, np.int16(new_audio * 32767))\n",
    "                    n+=1\n",
    "                    new_audio = np.zeros(split_audio[i+1][0]-split_audio[i][0])\n",
    "                else:\n",
    "                    new_audio = np.concatenate((new_audio, np.zeros(split_audio[i+1][0]-split_audio[i][1])))\n",
    "        \n",
    "        if len(new_audio) > 0:\n",
    "            write(os.path.join(save_path, (f\"{file.split('.')[0]}_noise_muted_{n}.{file.split('.')[1]}\")), \n",
    "                                           sampling_rate, np.int16(new_audio * 32767))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='./audio/'\n",
    "save_path='./trim_audio'\n",
    "\n",
    "# check if save path exists, else make it\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "mute_noise_chucked(data_path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}